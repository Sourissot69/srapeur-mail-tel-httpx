# Guide de Publication sur GitHub

## ğŸ“ PrÃ©paration

### 1. CrÃ©er un repository sur GitHub

1. Aller sur https://github.com
2. Cliquer sur "New repository"
3. Nom : `scraper-emails-reseaux-sociaux` (ou autre)
4. Description : "Scraper web pour extraire emails et rÃ©seaux sociaux avec systÃ¨me de queue"
5. Public ou Private (votre choix)
6. **NE PAS** cocher "Add README" (on a dÃ©jÃ  le nÃ´tre)
7. CrÃ©er le repository

### 2. Initialiser Git localement

Ouvrir un terminal dans le dossier du projet :

```bash
# Initialiser Git
git init

# Ajouter tous les fichiers
git add .

# Premier commit
git commit -m "Initial commit - Scraper avec systÃ¨me de queue"

# Ajouter le remote GitHub (remplacer par votre URL)
git remote add origin https://github.com/votre-username/scraper-emails-reseaux-sociaux.git

# Pousser sur GitHub
git branch -M main
git push -u origin main
```

## ğŸ”’ VÃ©rifications avant publication

### Fichiers Ã  NE PAS commiter (dÃ©jÃ  dans .gitignore)

âœ… **DÃ©jÃ  protÃ©gÃ© :**
- `*.csv` - Vos donnÃ©es CSV
- `results/*.json` - RÃ©sultats de scraping
- `queue/**/*.json` - Jobs en cours/terminÃ©s
- `*.log` - Logs
- `.env` - Configuration sensible
- `__pycache__/` - Cache Python

### Nettoyage avant publication

```bash
# Supprimer les rÃ©sultats locaux
rm -rf results/*.json
rm -rf queue/pending/*.json
rm -rf queue/processing/*.json
rm -rf queue/completed/*.json
rm -f *.log

# VÃ©rifier ce qui sera commitÃ©
git status
```

## ğŸ“„ README.md pour GitHub

Le README.md est dÃ©jÃ  optimisÃ© avec :
- âœ… Description claire
- âœ… Instructions d'installation
- âœ… Exemples d'utilisation
- âœ… Documentation systÃ¨me de queue
- âœ… Format des rÃ©sultats

## ğŸ·ï¸ Tags et Releases

### CrÃ©er une release

```bash
# CrÃ©er un tag
git tag -a v1.0.0 -m "Version 1.0.0 - SystÃ¨me de queue opÃ©rationnel"

# Pousser le tag
git push origin v1.0.0
```

Puis sur GitHub :
1. Aller dans "Releases"
2. "Create a new release"
3. Choisir le tag v1.0.0
4. Titre : "v1.0.0 - Premier release"
5. Description : Features + statistiques
6. Publier

## ğŸ“¦ Structure finale sur GitHub

```
votre-repo/
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ GUIDE_UTILISATION.txt
â”œâ”€â”€ DEPLOIEMENT_VPS.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â”œâ”€â”€ config.py
â”œâ”€â”€ scraper.py
â”œâ”€â”€ extractors.py
â”œâ”€â”€ utils.py
â”œâ”€â”€ add_job.py
â”œâ”€â”€ worker.py
â”œâ”€â”€ monitor.py
â”œâ”€â”€ run_scraper.py
â”œâ”€â”€ install_vps.sh
â”œâ”€â”€ install_service.sh
â”œâ”€â”€ deploy.sh
â”œâ”€â”€ queue/
â”‚   â”œâ”€â”€ pending/.gitkeep
â”‚   â”œâ”€â”€ processing/.gitkeep
â”‚   â””â”€â”€ completed/.gitkeep
â””â”€â”€ results/.gitkeep
```

## ğŸ¨ Badges GitHub (optionnel)

Ajouter en haut du README.md :

```markdown
![Python](https://img.shields.io/badge/python-3.7+-blue.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)
![Status](https://img.shields.io/badge/status-active-success.svg)
```

## ğŸ” Secrets GitHub (pour CI/CD futur)

Si vous voulez ajouter CI/CD plus tard :

1. Aller dans Settings â†’ Secrets and variables â†’ Actions
2. Ajouter :
   - `VPS_HOST` : IP du VPS
   - `VPS_USER` : Utilisateur SSH
   - `VPS_SSH_KEY` : ClÃ© SSH privÃ©e

## ğŸ“Š GitHub Actions (optionnel)

CrÃ©er `.github/workflows/deploy.yml` pour dÃ©ploiement automatique :

```yaml
name: Deploy to VPS

on:
  push:
    branches: [ main ]

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Deploy to VPS
        uses: appleboy/ssh-action@master
        with:
          host: ${{ secrets.VPS_HOST }}
          username: ${{ secrets.VPS_USER }}
          key: ${{ secrets.VPS_SSH_KEY }}
          script: |
            cd /opt/scrapeur-site-web
            git pull
            source venv/bin/activate
            pip install -r requirements.txt
            sudo systemctl restart scraper-worker
```

## âœ… Checklist avant publication

- [ ] Supprimer tous les CSV de donnÃ©es
- [ ] Supprimer tous les rÃ©sultats JSON
- [ ] Supprimer les logs
- [ ] VÃ©rifier .gitignore
- [ ] Tester git status (aucun fichier sensible)
- [ ] Modifier deploy.sh avec la vraie IP VPS
- [ ] README.md complet et clair
- [ ] License ajoutÃ©e (MIT ou autre)
- [ ] Tests effectuÃ©s localement

## ğŸ“ Description GitHub recommandÃ©e

**Short description :**
```
Scraper web asynchrone pour extraire emails et rÃ©seaux sociaux. SystÃ¨me de queue FIFO intÃ©grÃ©. ~2.5s/site. Python 3.7+
```

**Topics (tags) :**
- web-scraping
- python
- async
- httpx
- beautifulsoup
- email-extraction
- social-media
- queue-system
- google-maps

## ğŸ¯ PrÃªt pour publication !

AprÃ¨s ces Ã©tapes, votre projet sera :
- âœ… Sur GitHub (code source)
- âœ… DÃ©ployable sur VPS Hostinger en 1 commande
- âœ… Service systemd qui tourne 24/7
- âœ… Multi-utilisateurs avec queue
- âœ… Documentation complÃ¨te

