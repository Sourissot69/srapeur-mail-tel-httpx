# Documentation API Web - Port 8014

## üåê Base URL

```
http://VOTRE_IP_VPS:8014
```

## üìã Endpoints

### 1. Health Check

**GET** `/health`

V√©rifie que l'API fonctionne.

**R√©ponse :**
```json
{
  "status": "ok",
  "service": "Scraper API",
  "port": 8014,
  "timestamp": "2025-11-13T10:00:00"
}
```

---

### 2. Upload CSV

**POST** `/upload`

Upload un fichier CSV.

**Param√®tres :**
- `file` : Fichier CSV (multipart/form-data)

**Exemple (curl) :**
```bash
curl -X POST http://VOTRE_IP:8014/upload \
  -F "file=@mon_fichier.csv"
```

**R√©ponse :**
```json
{
  "success": true,
  "filename": "20251113_100000_mon_fichier.csv",
  "path": "uploads/20251113_100000_mon_fichier.csv"
}
```

---

### 3. Cr√©er un Job

**POST** `/job`

Cr√©e un job de scraping.

**Body (JSON) :**
```json
{
  "csv_file": "uploads/20251113_100000_mon_fichier.csv",
  "priority": 1,
  "user": "Alice"
}
```

**Param√®tres :**
- `csv_file` : Chemin vers le CSV (requis)
- `priority` : Priorit√© 1-10 (optionnel, d√©faut: 5)
- `user` : Nom utilisateur (optionnel, d√©faut: "API")

**Exemple (curl) :**
```bash
curl -X POST http://VOTRE_IP:8014/job \
  -H "Content-Type: application/json" \
  -d '{
    "csv_file": "uploads/mon_fichier.csv",
    "priority": 1,
    "user": "Alice"
  }'
```

**R√©ponse :**
```json
{
  "success": true,
  "message": "Job ajout√© √† la queue",
  "csv_file": "uploads/mon_fichier.csv",
  "priority": 1,
  "user": "Alice"
}
```

---

### 4. Upload + D√©marrer Job (Tout-en-un)

**POST** `/job/upload-and-start`

Upload un CSV et cr√©e le job imm√©diatement.

**Param√®tres (multipart/form-data) :**
- `file` : Fichier CSV
- `priority` : Priorit√© 1-10 (optionnel)
- `user` : Nom utilisateur (optionnel)

**Exemple (curl) :**
```bash
curl -X POST http://VOTRE_IP:8014/job/upload-and-start \
  -F "file=@mon_fichier.csv" \
  -F "priority=1" \
  -F "user=Alice"
```

**R√©ponse :**
```json
{
  "success": true,
  "message": "CSV upload√© et job ajout√©",
  "filename": "20251113_100000_mon_fichier.csv",
  "priority": 1
}
```

---

### 5. √âtat de la Queue

**GET** `/queue`

Obtient l'√©tat de la queue.

**Exemple :**
```bash
curl http://VOTRE_IP:8014/queue
```

**R√©ponse :**
```json
{
  "pending": 2,
  "processing": 1,
  "completed": 15,
  "pending_jobs": [
    {
      "id": "20251113_100000_123456",
      "csv_file": "avocats.csv",
      "user": "Alice",
      "priority": 1,
      "created_at": "2025-11-13T10:00:00"
    },
    {
      "id": "20251113_100030_789012",
      "csv_file": "pharmacies.csv",
      "user": "Bob",
      "priority": 5,
      "created_at": "2025-11-13T10:00:30"
    }
  ]
}
```

---

### 6. Liste des R√©sultats

**GET** `/results`

Liste tous les r√©sultats disponibles.

**Exemple :**
```bash
curl http://VOTRE_IP:8014/results
```

**R√©ponse :**
```json
{
  "count": 3,
  "results": [
    {
      "filename": "scraping_avocats_20251113_100530.json",
      "size": 15642,
      "created": "2025-11-13T10:05:30"
    },
    {
      "filename": "scraping_pharmacies_20251113_095230.json",
      "size": 23891,
      "created": "2025-11-13T09:52:30"
    }
  ]
}
```

---

### 7. T√©l√©charger un R√©sultat

**GET** `/results/<filename>`

T√©l√©charge un fichier de r√©sultats.

**Exemple :**
```bash
curl http://VOTRE_IP:8014/results/scraping_avocats_20251113_100530.json \
  --output resultat.json
```

---

## üîß D√©marrage de l'API

### Sur VPS (systemd) :
```bash
sudo systemctl start scraper-api
sudo systemctl enable scraper-api
```

### Manuel (d√©veloppement) :
```bash
python api_server.py
```

---

## üîí S√©curit√©

### Firewall
```bash
# Ouvrir le port 8014
sudo ufw allow 8014/tcp
sudo ufw reload
```

### Authentification (√Ä AJOUTER)

Pour s√©curiser l'API en production, ajoutez :
- Token d'authentification
- Rate limiting
- HTTPS avec certificat SSL

---

## üìä Exemple d'Utilisation Compl√®te

### Workflow avec l'API :

```bash
# 1. V√©rifier que l'API fonctionne
curl http://VOTRE_IP:8014/health

# 2. Upload CSV et cr√©er job
curl -X POST http://VOTRE_IP:8014/job/upload-and-start \
  -F "file=@mon_fichier.csv" \
  -F "priority=1" \
  -F "user=Alice"

# 3. V√©rifier l'√©tat de la queue
curl http://VOTRE_IP:8014/queue

# 4. Attendre fin du traitement (polling)
watch -n 5 'curl -s http://VOTRE_IP:8014/queue'

# 5. Lister les r√©sultats
curl http://VOTRE_IP:8014/results

# 6. T√©l√©charger le r√©sultat
curl http://VOTRE_IP:8014/results/scraping_mon_fichier_TIMESTAMP.json \
  --output resultat.json
```

---

## üêç Exemple avec Python

```python
import requests

# URL de l'API
API_URL = "http://VOTRE_IP:8014"

# 1. Upload et d√©marrer job
with open('mon_fichier.csv', 'rb') as f:
    response = requests.post(
        f"{API_URL}/job/upload-and-start",
        files={'file': f},
        data={'priority': 1, 'user': 'Alice'}
    )
    print(response.json())

# 2. V√©rifier l'√©tat
response = requests.get(f"{API_URL}/queue")
print(response.json())

# 3. Liste des r√©sultats
response = requests.get(f"{API_URL}/results")
results = response.json()['results']

# 4. T√©l√©charger le dernier r√©sultat
if results:
    filename = results[0]['filename']
    response = requests.get(f"{API_URL}/results/{filename}")
    with open('resultat.json', 'wb') as f:
        f.write(response.content)
```

---

## üåê Interface Web (Future)

Cr√©er une interface HTML simple pour :
- Upload CSV via drag & drop
- Voir l'√©tat de la queue en temps r√©el
- T√©l√©charger les r√©sultats

Fichier : `static/index.html` (√† cr√©er)

